{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import randint\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhnum</th>\n",
       "      <th>initintrvmon</th>\n",
       "      <th>startmon</th>\n",
       "      <th>initfinaldays</th>\n",
       "      <th>initialdate_flag</th>\n",
       "      <th>startdate_edit</th>\n",
       "      <th>startlag</th>\n",
       "      <th>matchconsenthh</th>\n",
       "      <th>nonmetro</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>feedback2</th>\n",
       "      <th>feedback3</th>\n",
       "      <th>feedback4_1</th>\n",
       "      <th>feedback4_2</th>\n",
       "      <th>feedback4_3</th>\n",
       "      <th>feedback4_4</th>\n",
       "      <th>feedback4_5</th>\n",
       "      <th>feedback4_6</th>\n",
       "      <th>feedback4_7</th>\n",
       "      <th>feedback4_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100015</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100024</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100028</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 279 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hhnum  initintrvmon  startmon  initfinaldays  initialdate_flag  \\\n",
       "0  100012             1         1              8                 0   \n",
       "1  100015             8         8              8                 0   \n",
       "2  100024             6         6              9                 0   \n",
       "3  100026             7         7             10                 0   \n",
       "4  100028             5         5              8                 0   \n",
       "\n",
       "   startdate_edit  startlag  matchconsenthh  nonmetro  region  ...  feedback2  \\\n",
       "0               0         1               1         1       3  ...        3.0   \n",
       "1               0         1               1         0       3  ...        6.0   \n",
       "2               0         0               1         0       2  ...        1.0   \n",
       "3               0         1               1         0       3  ...        1.0   \n",
       "4               0         1               1         0       1  ...        4.0   \n",
       "\n",
       "   feedback3  feedback4_1  feedback4_2  feedback4_3  feedback4_4  feedback4_5  \\\n",
       "0        3.0          0.0          0.0          0.0          0.0          0.0   \n",
       "1        2.0          0.0          0.0          0.0          0.0          0.0   \n",
       "2        1.0          0.0          0.0          0.0          0.0          0.0   \n",
       "3        1.0          0.0          0.0          0.0          0.0          0.0   \n",
       "4        1.0          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feedback4_6  feedback4_7  feedback4_8  \n",
       "0          0.0          0.0          1.0  \n",
       "1          0.0          0.0          1.0  \n",
       "2          0.0          0.0          1.0  \n",
       "3          0.0          0.0          1.0  \n",
       "4          0.0          0.0          1.0  \n",
       "\n",
       "[5 rows x 279 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing csv files\n",
    "\n",
    "# Household data\n",
    "hh_data = pd.read_csv(Path(\"Data/faps_household_puf.csv\"))\n",
    "hh_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhnum</th>\n",
       "      <th>infousa_flag</th>\n",
       "      <th>snap1</th>\n",
       "      <th>snap2</th>\n",
       "      <th>snap3</th>\n",
       "      <th>snap4</th>\n",
       "      <th>snap5</th>\n",
       "      <th>snap6</th>\n",
       "      <th>snap7</th>\n",
       "      <th>snap8</th>\n",
       "      <th>...</th>\n",
       "      <th>nonff8</th>\n",
       "      <th>nearff_sic1</th>\n",
       "      <th>nearff_sic2</th>\n",
       "      <th>nearff_dist</th>\n",
       "      <th>nearnonff_sic1</th>\n",
       "      <th>nearnonff_sic2</th>\n",
       "      <th>nearnonff_dist</th>\n",
       "      <th>nearmcd_sic1</th>\n",
       "      <th>nearmcd_sic2</th>\n",
       "      <th>nearmcd_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>188</td>\n",
       "      <td>...</td>\n",
       "      <td>222</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>0.30</td>\n",
       "      <td>581208</td>\n",
       "      <td>581208</td>\n",
       "      <td>0.30</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>0.527480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>43</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>118</td>\n",
       "      <td>512</td>\n",
       "      <td>...</td>\n",
       "      <td>113</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>0.21</td>\n",
       "      <td>581208</td>\n",
       "      <td>581208</td>\n",
       "      <td>0.20</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>1.546103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100024</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>67</td>\n",
       "      <td>275</td>\n",
       "      <td>327</td>\n",
       "      <td>382</td>\n",
       "      <td>...</td>\n",
       "      <td>220</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>0.85</td>\n",
       "      <td>581208</td>\n",
       "      <td>581208</td>\n",
       "      <td>0.37</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>0.846446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>69</td>\n",
       "      <td>408</td>\n",
       "      <td>...</td>\n",
       "      <td>98</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>10.93</td>\n",
       "      <td>581224</td>\n",
       "      <td>581224</td>\n",
       "      <td>1.70</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>11.987027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100028</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>90</td>\n",
       "      <td>125</td>\n",
       "      <td>294</td>\n",
       "      <td>...</td>\n",
       "      <td>250</td>\n",
       "      <td>541103</td>\n",
       "      <td>581208</td>\n",
       "      <td>0.86</td>\n",
       "      <td>581208</td>\n",
       "      <td>581208</td>\n",
       "      <td>0.46</td>\n",
       "      <td>581208</td>\n",
       "      <td>581206</td>\n",
       "      <td>1.441142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hhnum  infousa_flag  snap1  snap2  snap3  snap4  snap5  snap6  snap7  \\\n",
       "0  100012             1      0      4      9     16     19     22     37   \n",
       "1  100015             1      1      6     18     43     52     80    118   \n",
       "2  100024             1      0      0      2     10     67    275    327   \n",
       "3  100026             1      0      0      0      2      3     20     69   \n",
       "4  100028             1      0      1     12     40     64     90    125   \n",
       "\n",
       "   snap8  ...  nonff8  nearff_sic1  nearff_sic2  nearff_dist  nearnonff_sic1  \\\n",
       "0    188  ...     222       581208       581206         0.30          581208   \n",
       "1    512  ...     113       581208       581206         0.21          581208   \n",
       "2    382  ...     220       581208       581206         0.85          581208   \n",
       "3    408  ...      98       581208       581206        10.93          581224   \n",
       "4    294  ...     250       541103       581208         0.86          581208   \n",
       "\n",
       "   nearnonff_sic2  nearnonff_dist  nearmcd_sic1  nearmcd_sic2  nearmcd_dist  \n",
       "0          581208            0.30        581208        581206      0.527480  \n",
       "1          581208            0.20        581208        581206      1.546103  \n",
       "2          581208            0.37        581208        581206      0.846446  \n",
       "3          581224            1.70        581208        581206     11.987027  \n",
       "4          581208            0.46        581208        581206      1.441142  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Access data\n",
    "ac_data = pd.read_csv(Path(\"Data/faps_access_puf.csv\"))\n",
    "ac_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   eventid   hhnum  whogotpnum  athome       date  date_flag  startmon  \\\n",
      "0    65792  100012           1       1  1/10/2013          0         1   \n",
      "1    66220  100012           1       1  1/11/2013          0         1   \n",
      "2    66221  100012           1       1  1/12/2013          0         1   \n",
      "3    66222  100012           1       1  1/13/2013          0         1   \n",
      "4    66485  100012           2       1  1/14/2013          0         1   \n",
      "\n",
      "   daynum  daynum_flag    placeid  ...  booktype  bookpnum  startdate_flag  \\\n",
      "0       2            0  1017721.0  ...   Primary         1               0   \n",
      "1       3            0  1017721.0  ...   Primary         1               0   \n",
      "2       4            0  1017721.0  ...   Primary         1               0   \n",
      "3       5            0  1017721.0  ...   Primary         1               0   \n",
      "4       6            0  1017721.0  ...     Adult         2               0   \n",
      "\n",
      "   scandate_flag  abletoscanbp  abletoscanph  practice_flag  manualmatch_flag  \\\n",
      "0              0           1.0           0.0              0                 0   \n",
      "1              0           1.0           0.0              0                 0   \n",
      "2              0           1.0           0.0              0                 0   \n",
      "3              0           1.0           0.0              0                 0   \n",
      "4              0           1.0           0.0              0                 0   \n",
      "\n",
      "   moved_flag  multplaces_flag  \n",
      "0           0                0  \n",
      "1           0                0  \n",
      "2           0                0  \n",
      "3           0                0  \n",
      "4           0                0  \n",
      "\n",
      "[5 rows x 73 columns]\n",
      "   eventid   hhnum  whogotpnum  whogot_flag  athome  schoolmeal_flag  \\\n",
      "0    63198  100214           1            0       0                0   \n",
      "1    69123  101187           3            0       0                0   \n",
      "2    69124  101187           3            0       0                0   \n",
      "3    69126  101187           4            0       0                0   \n",
      "4    57499  101323          10            0       0                0   \n",
      "\n",
      "        date  date_flag  startmon  daynum  ...  booktype  bookpnum  whogotate  \\\n",
      "0  6/30/2012          2         6       6  ...   Primary         1          1   \n",
      "1  12/5/2012          0        12       1  ...     Youth         3          1   \n",
      "2  12/6/2012          0        12       2  ...     Youth         3          1   \n",
      "3  12/5/2012          0        12       1  ...     Youth         4          1   \n",
      "4  8/14/2012          0         8       7  ...     Youth        10          1   \n",
      "\n",
      "   bookownergot  bookownerate  bookownerate_flag  startdate_flag  \\\n",
      "0             1             1                  0               1   \n",
      "1             1             1                  0               0   \n",
      "2             1             1                  0               0   \n",
      "3             1             1                  0               0   \n",
      "4             1             1                  0               0   \n",
      "\n",
      "   practice_flag  capture_flag  frommemory  \n",
      "0              0             1           0  \n",
      "1              0             1           0  \n",
      "2              0             1           0  \n",
      "3              0             1           0  \n",
      "4              0             1           0  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "# Food at Home (FAH) and Food Away From Home (FAFH) data\n",
    "fah_data = pd.read_csv(Path(\"Data/faps_fahevent_puf.csv\"))\n",
    "print(fah_data.head())\n",
    "fafh_data = pd.read_csv(Path(\"Data/faps_fafhevent_puf.csv\"))\n",
    "print(fafh_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables of Interest\n",
    "merge on:\n",
    "- hhnum\n",
    "\n",
    "#### Y = predicting participation\n",
    "-      On SNAP (Y/N)\n",
    "    - snapnowhh \n",
    "#### X = six input variables, specifically:\n",
    "-      Monthly Household income (Columns AC-AG on household.csv)\n",
    "    - inchhavg_r\n",
    "-      Income excluding inputted amounts (Column AI on household.csv)\n",
    "-      Housing costs (Columns BC-BJ on household.csv)\n",
    "    - exprentmrtg_r, exphomeins_r,\texpproptax_r,\texppubtrans_r,\texpelectric_r,\texpheatfuel_r,\texpwastedisp_r\n",
    "-      Medical expenses (Columns BL-BN  on household.csv)\n",
    "    - exphealthins_r,\texpcopay_r,\texpdoctor_r,\texprx_r\n",
    "-      Household size (Column Q on household.csv)\n",
    "    - hhsize\n",
    "-      Average Distance to SNAP-authorized store (Columns AY-BD access.csv)\n",
    "    - dist_ss,\tdist_sm,\tdist_co,\tdist_cs,\tdist_mlg,\tdist_walmart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Household Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation Before Cleaning:\n",
    "- hhnum: 6-digit unique identifier for each household\n",
    "#### Household Data\n",
    "- snapnowhh: Anyone in household is receiving SNAP benefits (Y/N) \n",
    "- hhsize: Number of people at residence, excluding guests\n",
    "- inchhavg_r: Household average (monthly) income as sum of average imputed income per member (top-coded) \n",
    "- exprentmrtg_r: Household's monthly rent/mortgage expense (top-coded) \n",
    "- exphomeins_r: Household's monthly rental/homeowner's insurance expense (top coded) \n",
    "- expproptax_r: Householdâ€™s monthly property taxes (top-coded) \n",
    "- exppubtrans_r: Household's monthly public transport expense (top-coded) \n",
    "- expelectric_r: Household's monthly electricity expense (top-coded) \n",
    "- expheatfuel_r: Household's monthly heating fuel expense (top-coded) \n",
    "- expwastedisp_r: Household's monthly sewer/garbage removal expense (top-coded) \n",
    "- exphealthins_r: Household's monthly health insurance expense\n",
    "- expcopay_r: Household's monthly health insurance copays\n",
    "- expdoctor_r: Household's monthly doctor/hospital bills (top-coded)\n",
    "- exprx_r: Household's monthly prescription drug expense (top-coded)\n",
    "#### Access Data\n",
    "- dist_ss: Distance to nearest SNAP authorized super store, miles \n",
    "- dist_sm: Distance to nearest SNAP authorized supermarket, miles \n",
    "- dist_co: Distance to nearest SNAP authorized combination grocery/other store, miles \n",
    "- dist_cs: Distance to nearest SNAP authorized convenience store, miles \n",
    "- dist_mlg: Distance to nearest SNAP authorized grocery store (medium or large), miles \n",
    "- dist_walmart: Distance to nearest SNAP authorized Walmart, miles \n",
    "#### FAH Data\n",
    "- totalpaid: Total amount paid, including tax (and tip when FAFH)\n",
    "#### FAFH Data\n",
    "- totalpaid: Total amount paid, including tax (and tip when FAFH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4826 entries, 0 to 4825\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   hhnum           4826 non-null   int64  \n",
      " 1   snapnowhh       4826 non-null   int64  \n",
      " 2   inchhavg_r      4826 non-null   float64\n",
      " 3   hhsize          4826 non-null   int64  \n",
      " 4   exprentmrtg_r   4826 non-null   float64\n",
      " 5   exphomeins_r    4826 non-null   float64\n",
      " 6   expproptax_r    4826 non-null   float64\n",
      " 7   exppubtrans_r   4826 non-null   float64\n",
      " 8   expelectric_r   4826 non-null   float64\n",
      " 9   expheatfuel_r   4826 non-null   float64\n",
      " 10  expwastedisp_r  4826 non-null   float64\n",
      " 11  exphealthins_r  4826 non-null   float64\n",
      " 12  expcopay_r      4826 non-null   float64\n",
      " 13  expdoctor_r     4826 non-null   float64\n",
      " 14  exprx_r         4826 non-null   float64\n",
      "dtypes: float64(12), int64(3)\n",
      "memory usage: 565.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Reducing df to essential variables\n",
    "hh_df = hh_data[[\"hhnum\", \"snapnowhh\",\"inchhavg_r\", #hh number and avg household income\n",
    "                 \"hhsize\", # household size\n",
    "                 \"exprentmrtg_r\", \"exphomeins_r\",\t\"expproptax_r\",\t\"exppubtrans_r\",\t\"expelectric_r\",\t\"expheatfuel_r\",\t\"expwastedisp_r\", # household expenses\n",
    "                 \"exphealthins_r\",\t\"expcopay_r\",\t\"expdoctor_r\",\t\"exprx_r\" # healthcare costs/medical expenses\n",
    "                 ]]\n",
    "hh_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4078 entries, 0 to 4825\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   hhnum           4078 non-null   int64  \n",
      " 1   snapnowhh       4078 non-null   float64\n",
      " 2   inchhavg_r      4078 non-null   float64\n",
      " 3   hhsize          4078 non-null   int64  \n",
      " 4   exprentmrtg_r   4078 non-null   float64\n",
      " 5   exphomeins_r    4078 non-null   float64\n",
      " 6   expproptax_r    4078 non-null   float64\n",
      " 7   exppubtrans_r   4078 non-null   float64\n",
      " 8   expelectric_r   4078 non-null   float64\n",
      " 9   expheatfuel_r   4078 non-null   float64\n",
      " 10  expwastedisp_r  4078 non-null   float64\n",
      " 11  exphealthins_r  4078 non-null   float64\n",
      " 12  expcopay_r      4078 non-null   float64\n",
      " 13  expdoctor_r     4078 non-null   float64\n",
      " 14  exprx_r         4078 non-null   float64\n",
      "dtypes: float64(13), int64(2)\n",
      "memory usage: 509.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Need to get rid of the negative values that are used for stand ins for missing values\n",
    "    # NOTE: the snapnowhh variable is boolean with 0 and 1 meaning no and yes\n",
    "\n",
    "hh_df_filtered = hh_df[hh_df >= 0].dropna()\n",
    "hh_df_filtered.info()\n",
    "    # Data is now 4087 rows long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhnum</th>\n",
       "      <th>snapnowhh</th>\n",
       "      <th>inchhavg_r</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>hh_expenses</th>\n",
       "      <th>med_expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4667.33</td>\n",
       "      <td>5</td>\n",
       "      <td>806.0</td>\n",
       "      <td>429.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1</td>\n",
       "      <td>378.0</td>\n",
       "      <td>243.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5024.50</td>\n",
       "      <td>2</td>\n",
       "      <td>1362.0</td>\n",
       "      <td>365.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>2</td>\n",
       "      <td>132.0</td>\n",
       "      <td>496.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3998.00</td>\n",
       "      <td>7</td>\n",
       "      <td>731.0</td>\n",
       "      <td>34.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hhnum  snapnowhh  inchhavg_r  hhsize  hh_expenses  med_expenses\n",
       "0  100012        1.0     4667.33       5        806.0        429.67\n",
       "1  100015        0.0     1200.00       1        378.0        243.00\n",
       "2  100024        0.0     5024.50       2       1362.0        365.00\n",
       "3  100026        0.0     1800.00       2        132.0        496.83\n",
       "4  100028        1.0     3998.00       7        731.0         34.00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating aggregate columns\n",
    "\n",
    "# Household Expenses\n",
    "hh_df_filtered[\"hh_expenses\"] = hh_df_filtered[[\"exprentmrtg_r\", \"exphomeins_r\",\t\"expproptax_r\",\t\"exppubtrans_r\",\t\"expelectric_r\",\t\"expheatfuel_r\",\t\"expwastedisp_r\"]].sum(axis=1)\n",
    "# Medical Costs\n",
    "hh_df_filtered[\"med_expenses\"] = hh_df_filtered[[\"exphealthins_r\",\t\"expcopay_r\",\t\"expdoctor_r\",\t\"exprx_r\"]].sum(axis=1)\n",
    "\n",
    "#dropping extraneous columns\n",
    "hh_df_filtered = hh_df_filtered.drop(hh_df.iloc[:, 4:15], axis=1)\n",
    "hh_df_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhnum</th>\n",
       "      <th>snapnowhh</th>\n",
       "      <th>inchhavg_r</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>hh_expenses</th>\n",
       "      <th>med_expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012</td>\n",
       "      <td>1</td>\n",
       "      <td>4667.33</td>\n",
       "      <td>5</td>\n",
       "      <td>161.20</td>\n",
       "      <td>85.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100015</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1</td>\n",
       "      <td>378.00</td>\n",
       "      <td>243.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100024</td>\n",
       "      <td>0</td>\n",
       "      <td>5024.50</td>\n",
       "      <td>2</td>\n",
       "      <td>681.00</td>\n",
       "      <td>182.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>0</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>2</td>\n",
       "      <td>66.00</td>\n",
       "      <td>248.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100028</td>\n",
       "      <td>1</td>\n",
       "      <td>3998.00</td>\n",
       "      <td>7</td>\n",
       "      <td>104.43</td>\n",
       "      <td>4.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hhnum  snapnowhh  inchhavg_r  hhsize  hh_expenses  med_expenses\n",
       "0  100012          1     4667.33       5       161.20         85.93\n",
       "1  100015          0     1200.00       1       378.00        243.00\n",
       "2  100024          0     5024.50       2       681.00        182.50\n",
       "3  100026          0     1800.00       2        66.00        248.42\n",
       "4  100028          1     3998.00       7       104.43          4.86"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Averaging the data by household size\n",
    "# also round to two decimal places for simplicity\n",
    "hh_df_filtered[[\"hh_expenses\", \"med_expenses\"]] = hh_df_filtered[[\"hh_expenses\", \"med_expenses\"]].\\\n",
    "                                        div(hh_df_filtered[\"hhsize\"], axis=0).\\\n",
    "                                        round(2)\n",
    "\n",
    "hh_df_filtered[\"snapnowhh\"] = hh_df_filtered[\"snapnowhh\"].astype(int)\n",
    "\n",
    "hh_df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhnum</th>\n",
       "      <th>sum_snap_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012</td>\n",
       "      <td>3.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100015</td>\n",
       "      <td>5.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100024</td>\n",
       "      <td>17.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>42.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100028</td>\n",
       "      <td>10.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    hhnum  sum_snap_dist\n",
       "0  100012           3.83\n",
       "1  100015           5.43\n",
       "2  100024          17.59\n",
       "3  100026          42.23\n",
       "4  100028          10.25"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reducing to necessary columns, same steps as above\n",
    "ac_df = ac_data[[\"hhnum\", \"dist_ss\",\t\"dist_sm\",\t\"dist_co\",\t\"dist_cs\",\t\"dist_mlg\",\t\"dist_walmart\"]] # distance to nearest SNAP-authorized establishment\n",
    "\n",
    "# dropping any rows with missing values\n",
    "filtered_ac_df = ac_df[ac_df >= 0].dropna()\n",
    "\n",
    "#creating an aggregate column\n",
    "filtered_ac_df[\"sum_snap_dist\"] = ac_df.iloc[:,1:7].sum(axis=1)  \n",
    "\n",
    "# dropping the extraneous columns after aggregation\n",
    "filtered_ac_df = filtered_ac_df.drop(filtered_ac_df.iloc[:,1:7], axis=1) # dropping the extraneous columns after aggregation\n",
    "filtered_ac_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FAH and FAFH data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhnum</th>\n",
       "      <th>fah_paid</th>\n",
       "      <th>fafh_paid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100012</td>\n",
       "      <td>9.62</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100012</td>\n",
       "      <td>39.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100012</td>\n",
       "      <td>54.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100012</td>\n",
       "      <td>5.34</td>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15993</th>\n",
       "      <td>120078</td>\n",
       "      <td>1.22</td>\n",
       "      <td>12.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15994</th>\n",
       "      <td>120078</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>120080</td>\n",
       "      <td>11.55</td>\n",
       "      <td>15.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>120080</td>\n",
       "      <td>10.54</td>\n",
       "      <td>9.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>120080</td>\n",
       "      <td>21.64</td>\n",
       "      <td>12.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15739 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        hhnum  fah_paid  fafh_paid\n",
       "0      100012      1.80       1.99\n",
       "2      100012      9.62       0.00\n",
       "3      100012     39.75       0.00\n",
       "4      100012     54.67       0.00\n",
       "5      100012      5.34      51.00\n",
       "...       ...       ...        ...\n",
       "15993  120078      1.22      12.93\n",
       "15994  120078      0.00      12.96\n",
       "15995  120080     11.55      15.48\n",
       "15996  120080     10.54       9.07\n",
       "15997  120080     21.64      12.70\n",
       "\n",
       "[15739 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is info on the total amount of money spent for food at home and food away from home\n",
    "food_df = pd.DataFrame()\n",
    "\n",
    "# creating the columns for costs, including the hhnum variable for indexing\n",
    "food_df[[\"hhnum\",\"fah_paid\"]] = fah_data[[\"hhnum\",\"totalpaid\"]]\n",
    "food_df[\"fafh_paid\"] = fafh_data[\"totalpaid\"]\n",
    "\n",
    "# dropping missing values\n",
    "food_df_filtered = food_df[food_df >= 0].dropna()\n",
    "food_df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fah_paid</th>\n",
       "      <th>fafh_paid</th>\n",
       "      <th>totalpaid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hhnum</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100012</th>\n",
       "      <td>111.18</td>\n",
       "      <td>52.99</td>\n",
       "      <td>164.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100015</th>\n",
       "      <td>17.65</td>\n",
       "      <td>54.60</td>\n",
       "      <td>72.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100024</th>\n",
       "      <td>82.97</td>\n",
       "      <td>277.43</td>\n",
       "      <td>360.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100026</th>\n",
       "      <td>122.95</td>\n",
       "      <td>16.03</td>\n",
       "      <td>138.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100028</th>\n",
       "      <td>88.99</td>\n",
       "      <td>10.00</td>\n",
       "      <td>98.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120049</th>\n",
       "      <td>68.61</td>\n",
       "      <td>21.86</td>\n",
       "      <td>90.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120067</th>\n",
       "      <td>0.00</td>\n",
       "      <td>13.59</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120077</th>\n",
       "      <td>13.89</td>\n",
       "      <td>2.37</td>\n",
       "      <td>16.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120078</th>\n",
       "      <td>4.26</td>\n",
       "      <td>30.68</td>\n",
       "      <td>34.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120080</th>\n",
       "      <td>43.73</td>\n",
       "      <td>37.25</td>\n",
       "      <td>80.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4401 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fah_paid  fafh_paid  totalpaid\n",
       "hhnum                                 \n",
       "100012    111.18      52.99     164.17\n",
       "100015     17.65      54.60      72.25\n",
       "100024     82.97     277.43     360.40\n",
       "100026    122.95      16.03     138.98\n",
       "100028     88.99      10.00      98.99\n",
       "...          ...        ...        ...\n",
       "120049     68.61      21.86      90.47\n",
       "120067      0.00      13.59      13.59\n",
       "120077     13.89       2.37      16.26\n",
       "120078      4.26      30.68      34.94\n",
       "120080     43.73      37.25      80.98\n",
       "\n",
       "[4401 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aggregating the costs by household\n",
    "food_df_agg = food_df_filtered.groupby(\"hhnum\").sum()\n",
    "food_df_agg[\"totalpaid\"] = food_df_agg.iloc[:,0:2].sum(axis=1)\n",
    "\n",
    "food_df_agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inner join on the dataframes\n",
    "snap_df = hh_df_filtered.merge(filtered_ac_df, on=\"hhnum\")\n",
    "snap_df = snap_df.merge(food_df_agg, on=\"hhnum\")\n",
    "snap_df\n",
    "\n",
    "\n",
    "# Finally, averaging amount paid for food by household size\n",
    "snap_df[[\"fah_paid\",\"fafh_paid\",\"totalpaid\"]] = snap_df[[\"fah_paid\",\"fafh_paid\",\"totalpaid\"]].div(snap_df[\"hhsize\"], axis=0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset Info\n",
    "- 3722 rows Ã— 10 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Documentation After Cleaning\n",
    "- hhnum: 6-digit unique identifier for each household\n",
    "- snapnowhh: Anyone in household is receiving SNAP benefits (Y/N)\n",
    "- inchhavg_r: Household average (monthly) income as sum of average imputed income per member (top-coded) \n",
    "- hhsize: Number of people at residence, excluding guests\n",
    "- hh_expenses: sum of household expenditures, averaged by household size\n",
    "- med_expenses: sum of medical costs (insurance, rx, etc), averaged by household size\n",
    "- sum_snap_dist: sum of distance to nearest SNAP-authorized establishment\n",
    "- fah_paid: Total amount paid for food at home, including tax\n",
    "- fafh_paid: Total amount paid for food away from home, including tax (and tip when FAFH)\n",
    "- totalpaid: Total amount paid for both FAH and FAFH, including tax (and tip when FAFH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hhnum</th>\n",
       "      <th>snapnowhh</th>\n",
       "      <th>inchhavg_r</th>\n",
       "      <th>hhsize</th>\n",
       "      <th>hh_expenses</th>\n",
       "      <th>med_expenses</th>\n",
       "      <th>sum_snap_dist</th>\n",
       "      <th>fah_paid</th>\n",
       "      <th>fafh_paid</th>\n",
       "      <th>totalpaid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100012</td>\n",
       "      <td>1</td>\n",
       "      <td>4667.33</td>\n",
       "      <td>5</td>\n",
       "      <td>161.20</td>\n",
       "      <td>85.93</td>\n",
       "      <td>3.83</td>\n",
       "      <td>22.24</td>\n",
       "      <td>10.60</td>\n",
       "      <td>32.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100015</td>\n",
       "      <td>0</td>\n",
       "      <td>1200.00</td>\n",
       "      <td>1</td>\n",
       "      <td>378.00</td>\n",
       "      <td>243.00</td>\n",
       "      <td>5.43</td>\n",
       "      <td>17.65</td>\n",
       "      <td>54.60</td>\n",
       "      <td>72.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100024</td>\n",
       "      <td>0</td>\n",
       "      <td>5024.50</td>\n",
       "      <td>2</td>\n",
       "      <td>681.00</td>\n",
       "      <td>182.50</td>\n",
       "      <td>17.59</td>\n",
       "      <td>41.48</td>\n",
       "      <td>138.72</td>\n",
       "      <td>180.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100026</td>\n",
       "      <td>0</td>\n",
       "      <td>1800.00</td>\n",
       "      <td>2</td>\n",
       "      <td>66.00</td>\n",
       "      <td>248.42</td>\n",
       "      <td>42.23</td>\n",
       "      <td>61.48</td>\n",
       "      <td>8.02</td>\n",
       "      <td>69.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100028</td>\n",
       "      <td>1</td>\n",
       "      <td>3998.00</td>\n",
       "      <td>7</td>\n",
       "      <td>104.43</td>\n",
       "      <td>4.86</td>\n",
       "      <td>10.25</td>\n",
       "      <td>12.71</td>\n",
       "      <td>1.43</td>\n",
       "      <td>14.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>120049</td>\n",
       "      <td>0</td>\n",
       "      <td>2200.00</td>\n",
       "      <td>2</td>\n",
       "      <td>339.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.72</td>\n",
       "      <td>34.30</td>\n",
       "      <td>10.93</td>\n",
       "      <td>45.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3718</th>\n",
       "      <td>120067</td>\n",
       "      <td>1</td>\n",
       "      <td>2500.00</td>\n",
       "      <td>7</td>\n",
       "      <td>118.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>39.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>1.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3719</th>\n",
       "      <td>120077</td>\n",
       "      <td>1</td>\n",
       "      <td>1009.00</td>\n",
       "      <td>1</td>\n",
       "      <td>553.89</td>\n",
       "      <td>24.00</td>\n",
       "      <td>47.67</td>\n",
       "      <td>13.89</td>\n",
       "      <td>2.37</td>\n",
       "      <td>16.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3720</th>\n",
       "      <td>120078</td>\n",
       "      <td>1</td>\n",
       "      <td>523.60</td>\n",
       "      <td>2</td>\n",
       "      <td>193.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.17</td>\n",
       "      <td>2.13</td>\n",
       "      <td>15.34</td>\n",
       "      <td>17.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3721</th>\n",
       "      <td>120080</td>\n",
       "      <td>0</td>\n",
       "      <td>2352.00</td>\n",
       "      <td>1</td>\n",
       "      <td>434.00</td>\n",
       "      <td>458.00</td>\n",
       "      <td>12.39</td>\n",
       "      <td>43.73</td>\n",
       "      <td>37.25</td>\n",
       "      <td>80.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3722 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hhnum  snapnowhh  inchhavg_r  hhsize  hh_expenses  med_expenses  \\\n",
       "0     100012          1     4667.33       5       161.20         85.93   \n",
       "1     100015          0     1200.00       1       378.00        243.00   \n",
       "2     100024          0     5024.50       2       681.00        182.50   \n",
       "3     100026          0     1800.00       2        66.00        248.42   \n",
       "4     100028          1     3998.00       7       104.43          4.86   \n",
       "...      ...        ...         ...     ...          ...           ...   \n",
       "3717  120049          0     2200.00       2       339.00          0.00   \n",
       "3718  120067          1     2500.00       7       118.57          0.00   \n",
       "3719  120077          1     1009.00       1       553.89         24.00   \n",
       "3720  120078          1      523.60       2       193.50          0.00   \n",
       "3721  120080          0     2352.00       1       434.00        458.00   \n",
       "\n",
       "      sum_snap_dist  fah_paid  fafh_paid  totalpaid  \n",
       "0              3.83     22.24      10.60      32.83  \n",
       "1              5.43     17.65      54.60      72.25  \n",
       "2             17.59     41.48     138.72     180.20  \n",
       "3             42.23     61.48       8.02      69.49  \n",
       "4             10.25     12.71       1.43      14.14  \n",
       "...             ...       ...        ...        ...  \n",
       "3717           5.72     34.30      10.93      45.24  \n",
       "3718          39.43      0.00       1.94       1.94  \n",
       "3719          47.67     13.89       2.37      16.26  \n",
       "3720          70.17      2.13      15.34      17.47  \n",
       "3721          12.39     43.73      37.25      80.98  \n",
       "\n",
       "[3722 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snap_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: DATA VISUALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running model with all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X (features) and y (target)\n",
    "# The y variable should focus on the target column\n",
    "y = snap_df['snapnowhh']\n",
    "\n",
    "# The X variable should include all features except the target\n",
    "X = snap_df.drop(columns=['snapnowhh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X before splitting\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into testing and training sets using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a logistic regression model.\n",
    "logistic_regression_model = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "\n",
    "# Fit and save the logistic regression model using the training data\n",
    "lr_model = logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training predictions\n",
    "training_predictions = logistic_regression_model.predict(X_train)\n",
    "\n",
    "# Generate testing predictions\n",
    "testing_predictions = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1616  245]\n",
      " [ 355  575]]\n"
     ]
    }
   ],
   "source": [
    "# Create and save the confusion matrix for the training data\n",
    "training_matrix = confusion_matrix(y_train, training_predictions)\n",
    "\n",
    "# Print the confusion matrix for the training data\n",
    "print(training_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[547  74]\n",
      " [112 198]]\n"
     ]
    }
   ],
   "source": [
    "# Create and save the confusion matrix for the testing data\n",
    "test_matrix = confusion_matrix(y_test, testing_predictions)\n",
    "\n",
    "# Print the confusion matrix for the testing data\n",
    "print(test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Participating [labeled 1]       0.82      0.87      0.84      1861\n",
      "Not Participating [labeled 0]       0.70      0.62      0.66       930\n",
      "\n",
      "                     accuracy                           0.79      2791\n",
      "                    macro avg       0.76      0.74      0.75      2791\n",
      "                 weighted avg       0.78      0.79      0.78      2791\n",
      "\n",
      "Testing Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Participating [labeled 1]       0.83      0.88      0.85       621\n",
      "Not Participating [labeled 0]       0.73      0.64      0.68       310\n",
      "\n",
      "                     accuracy                           0.80       931\n",
      "                    macro avg       0.78      0.76      0.77       931\n",
      "                 weighted avg       0.80      0.80      0.80       931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and save the training classification report\n",
    "class_labels = [\"Participating [labeled 1]\", \"Not Participating [labeled 0]\"]\n",
    "\n",
    "# Create and print the training classification report\n",
    "training_report = classification_report(y_train, training_predictions, target_names=class_labels)\n",
    "print(\"Training Classification Report:\\n\", training_report)\n",
    "\n",
    "# Create and print the testing classification report\n",
    "testing_report = classification_report(y_test, testing_predictions, target_names=class_labels)\n",
    "print(\"Testing Classification Report:\\n\", testing_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Model Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing to two features [fah_paid and fafh_paid] to try and improve model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into X (features) and y (target)\n",
    "# The y variable should focus on the target column\n",
    "y_2 = snap_df['snapnowhh']\n",
    "\n",
    "# The X variable should include all features except the target\n",
    "X_2 = snap_df.drop(columns=['snapnowhh', 'fah_paid', 'fafh_paid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X before splitting\n",
    "scaler = StandardScaler()\n",
    "X_scaled_2 = scaler.fit_transform(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into testing and training sets using train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled_2, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a logistic regression model.\n",
    "logistic_regression_model = LogisticRegression(solver='lbfgs', random_state=42)\n",
    "\n",
    "# Fit and save the logistic regression model using the training data\n",
    "lr_model = logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training predictions\n",
    "training_predictions_2 = logistic_regression_model.predict(X_train)\n",
    "\n",
    "# Generate testing predictions\n",
    "testing_predictions_2 = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1617  244]\n",
      " [ 357  573]]\n"
     ]
    }
   ],
   "source": [
    "# Create and save the confusion matrix for the training data\n",
    "training_matrix_2 = confusion_matrix(y_train, training_predictions_2)\n",
    "\n",
    "# Print the confusion matrix for the training data\n",
    "print(training_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[547  74]\n",
      " [112 198]]\n"
     ]
    }
   ],
   "source": [
    "# Create and save the confusion matrix for the testing data\n",
    "test_matrix_2 = confusion_matrix(y_test, testing_predictions_2)\n",
    "\n",
    "# Print the confusion matrix for the testing data\n",
    "print(test_matrix_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Classification Report 2:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Participating [labeled 1]       0.82      0.87      0.84      1861\n",
      "Not Participating [labeled 0]       0.70      0.62      0.66       930\n",
      "\n",
      "                     accuracy                           0.78      2791\n",
      "                    macro avg       0.76      0.74      0.75      2791\n",
      "                 weighted avg       0.78      0.78      0.78      2791\n",
      "\n",
      "Testing Classification Report 2:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Participating [labeled 1]       0.83      0.88      0.85       621\n",
      "Not Participating [labeled 0]       0.73      0.64      0.68       310\n",
      "\n",
      "                     accuracy                           0.80       931\n",
      "                    macro avg       0.78      0.76      0.77       931\n",
      "                 weighted avg       0.80      0.80      0.80       931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and save the training classification report\n",
    "class_labels = [\"Participating [labeled 1]\", \"Not Participating [labeled 0]\"]\n",
    "\n",
    "# Create and print the training classification report\n",
    "training_report_2 = classification_report(y_train, training_predictions_2, target_names=class_labels)\n",
    "print(\"Training Classification Report 2:\\n\", training_report_2)\n",
    "\n",
    "# Create and print the testing classification report\n",
    "testing_report_2 = classification_report(y_test, testing_predictions_2, target_names=class_labels)\n",
    "print(\"Testing Classification Report 2:\\n\", testing_report_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CONCLUSION: NO IMPROVEMENT TO MODEL ACCURACY BY REMOVING FEATURES, fah_paid and fafh_paid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 4: RANDOM FOREST ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest classifier\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 1000),\n",
    "    'max_depth': randint(5, 20),\n",
    "    'min_samples_split': randint(2, 11)\n",
    "}\n",
    "\n",
    "# Create RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=10, cv=5)\n",
    "\n",
    "# Fit the RandomizedSearchCV object to your data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and estimator\n",
    "best_params = random_search.best_params_\n",
    "best_model = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 9, 'min_samples_split': 6, 'n_estimators': 259}\n",
      "Predictions: [1 0 0 1 0 0 1 0 1 0 0 0 0 1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 0 1 1 1 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 1 0 0 0 1 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 1 0 1 1 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 1 1 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 1 0\n",
      " 0 1 1 0 1 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 1 0 1 0 1 0 1 0 1 0 0 0 1\n",
      " 0 0 0 1 0 1 0 0 1 0 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 1 1 0 1 1 0 0 1 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 0 0 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 1 0 0 1 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0\n",
      " 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 1\n",
      " 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1\n",
      " 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 1 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Print the best parameters\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "# Use the best model for further predictions or evaluation and print\n",
    "predictions = best_model.predict(X_test)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Classification Report:\n",
      "                                precision    recall  f1-score   support\n",
      "\n",
      "    Participating [labeled 1]       0.83      0.90      0.86       621\n",
      "Not Participating [labeled 0]       0.75      0.62      0.68       310\n",
      "\n",
      "                     accuracy                           0.80       931\n",
      "                    macro avg       0.79      0.76      0.77       931\n",
      "                 weighted avg       0.80      0.80      0.80       931\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create, then print classification report\n",
    "testing_report = classification_report(y_test, predictions, target_names=class_labels)\n",
    "print(\"Testing Classification Report:\\n\", testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['hhnum', 'inchhavg_r', 'hhsize', 'hh_expenses', 'med_expenses',\n",
      "       'sum_snap_dist', 'totalpaid'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Generate feature importances and feature names\n",
    "feature_importances = best_model.feature_importances_\n",
    "feature_names = X_2.columns\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and sort a DataFrame for visualization\n",
    "importance_df = pd.DataFrame({'feature': feature_names, 'importance': feature_importances})\n",
    "importance_df = importance_df.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build plot\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'], color='blue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature Name')\n",
    "plt.title('Feature Importances in Random Forest Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 5: NEURAL NETWORK TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST ITERATION - 4 layers; neurons = 75; 37; 18, 1; activation = relu; and epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features: 7\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# Checking the number of possible input features\n",
    "count_input_features = X_train.shape[1]\n",
    "print(\"Number of input features:\", count_input_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 75)                600       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 37)                2812      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 18)                684       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,115\n",
      "Trainable params: 4,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Configuring layers and nodes\n",
    "snap_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "snap_model.add(tf.keras.layers.Dense(units=75, activation=\"relu\", input_dim=count_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "snap_model.add(tf.keras.layers.Dense(units=37, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "snap_model.add(tf.keras.layers.Dense(units=18, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "snap_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "snap_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "snap_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 0.5495 - accuracy: 0.7309\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.7782\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.7857\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.7854\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4549 - accuracy: 0.7865\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4508 - accuracy: 0.7933\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4479 - accuracy: 0.7908\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4467 - accuracy: 0.7958\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7958\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7951\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.7961\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.7943\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4352 - accuracy: 0.7997\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7933\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8001\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.8011\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7968\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7972\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.7968\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4251 - accuracy: 0.8022\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.7990\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4230 - accuracy: 0.8001\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4201 - accuracy: 0.8062\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4183 - accuracy: 0.8033\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8008\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4189 - accuracy: 0.8022\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4144 - accuracy: 0.8004\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8069\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4137 - accuracy: 0.8001\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4126 - accuracy: 0.8058\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4106 - accuracy: 0.8123\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4107 - accuracy: 0.8008\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4063 - accuracy: 0.8087\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8105\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4041 - accuracy: 0.8083\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4050 - accuracy: 0.8069\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4043 - accuracy: 0.8076\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3999 - accuracy: 0.8155\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8108\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3983 - accuracy: 0.8130\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.8076\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8119\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8151\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8194\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3872 - accuracy: 0.8166\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3928 - accuracy: 0.8183\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8144\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8237\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8212\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3871 - accuracy: 0.8162\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3825 - accuracy: 0.8187\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3786 - accuracy: 0.8209\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3775 - accuracy: 0.8255\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3791 - accuracy: 0.8219\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3725 - accuracy: 0.8305\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3733 - accuracy: 0.8244\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3745 - accuracy: 0.8194\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8287\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3713 - accuracy: 0.8198\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3658 - accuracy: 0.8302\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8348\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3657 - accuracy: 0.8277\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.8348\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3586 - accuracy: 0.8330\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3577 - accuracy: 0.8334\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3562 - accuracy: 0.8316\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8305\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3545 - accuracy: 0.8341\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8363\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3518 - accuracy: 0.8391\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3455 - accuracy: 0.8452\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8391\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8420\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8370\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8424\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3398 - accuracy: 0.8449\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8359\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8424\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3403 - accuracy: 0.8477\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3343 - accuracy: 0.8438\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3309 - accuracy: 0.8488\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8509\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3341 - accuracy: 0.8474\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3286 - accuracy: 0.8484\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3253 - accuracy: 0.8531\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3311 - accuracy: 0.8424\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3260 - accuracy: 0.8481\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8495\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8492\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8574\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8592\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8538\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8552\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8624\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8563\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8570\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8563\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8574\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3069 - accuracy: 0.8538\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8585\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = snap_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 0s - loss: 0.5740 - accuracy: 0.7411 - 240ms/epoch - 8ms/step\n",
      "Loss: 0.5739845633506775, Accuracy: 0.7411385774612427\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = snap_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "snap_model.save(\"snap_participation.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SECOND ITERATION - 4 layers; neurons = 75; 37; 18, 1; activation = tanh; and epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 75)                600       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 37)                2812      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 18)                684       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 19        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,115\n",
      "Trainable params: 4,115\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Configuring layers and nodes\n",
    "snap_model_2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "snap_model_2.add(tf.keras.layers.Dense(units=75, activation=\"tanh\", input_dim=count_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "snap_model_2.add(tf.keras.layers.Dense(units=37, activation=\"tanh\"))\n",
    "\n",
    "# Third hidden layer\n",
    "snap_model_2.add(tf.keras.layers.Dense(units=18, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "snap_model_2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "snap_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "snap_model_2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "88/88 [==============================] - 1s 2ms/step - loss: 0.5194 - accuracy: 0.7374\n",
      "Epoch 2/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.7832\n",
      "Epoch 3/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.7804\n",
      "Epoch 4/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.7861\n",
      "Epoch 5/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.7857\n",
      "Epoch 6/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7847\n",
      "Epoch 7/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4568 - accuracy: 0.7829\n",
      "Epoch 8/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7818\n",
      "Epoch 9/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7854\n",
      "Epoch 10/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7868\n",
      "Epoch 11/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4554 - accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4510 - accuracy: 0.7908\n",
      "Epoch 13/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4529 - accuracy: 0.7918\n",
      "Epoch 14/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7908\n",
      "Epoch 15/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4481 - accuracy: 0.7911\n",
      "Epoch 16/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4494 - accuracy: 0.7918\n",
      "Epoch 17/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4471 - accuracy: 0.7904\n",
      "Epoch 18/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.7915\n",
      "Epoch 19/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4449 - accuracy: 0.7922\n",
      "Epoch 20/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4450 - accuracy: 0.7925\n",
      "Epoch 21/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4425 - accuracy: 0.7976\n",
      "Epoch 22/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4402 - accuracy: 0.7958\n",
      "Epoch 23/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4430 - accuracy: 0.7933\n",
      "Epoch 24/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4429 - accuracy: 0.7965\n",
      "Epoch 25/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7922\n",
      "Epoch 26/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4398 - accuracy: 0.7936\n",
      "Epoch 27/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4377 - accuracy: 0.7933\n",
      "Epoch 28/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.7968\n",
      "Epoch 29/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.7915\n",
      "Epoch 30/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4355 - accuracy: 0.8019\n",
      "Epoch 31/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.7994\n",
      "Epoch 32/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.7994\n",
      "Epoch 33/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8040\n",
      "Epoch 34/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4329 - accuracy: 0.7933\n",
      "Epoch 35/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4333 - accuracy: 0.7958\n",
      "Epoch 36/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4314 - accuracy: 0.7961\n",
      "Epoch 37/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.8015\n",
      "Epoch 38/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7972\n",
      "Epoch 39/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7965\n",
      "Epoch 40/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8004\n",
      "Epoch 41/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4259 - accuracy: 0.8044\n",
      "Epoch 42/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8037\n",
      "Epoch 43/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8033\n",
      "Epoch 44/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8040\n",
      "Epoch 45/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4228 - accuracy: 0.8033\n",
      "Epoch 46/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4242 - accuracy: 0.8022\n",
      "Epoch 47/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4247 - accuracy: 0.8001\n",
      "Epoch 48/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4216 - accuracy: 0.8051\n",
      "Epoch 49/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4220 - accuracy: 0.8019\n",
      "Epoch 50/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4221 - accuracy: 0.8011\n",
      "Epoch 51/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4205 - accuracy: 0.8004\n",
      "Epoch 52/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4176 - accuracy: 0.8051\n",
      "Epoch 53/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4163 - accuracy: 0.8033\n",
      "Epoch 54/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8069\n",
      "Epoch 55/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4164 - accuracy: 0.8004\n",
      "Epoch 56/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4150 - accuracy: 0.8033\n",
      "Epoch 57/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4130 - accuracy: 0.8040\n",
      "Epoch 58/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4119 - accuracy: 0.8076\n",
      "Epoch 59/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.8062\n",
      "Epoch 60/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8051\n",
      "Epoch 61/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4108 - accuracy: 0.8040\n",
      "Epoch 62/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4072 - accuracy: 0.8148\n",
      "Epoch 63/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8080\n",
      "Epoch 64/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4060 - accuracy: 0.8062\n",
      "Epoch 65/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4055 - accuracy: 0.8094\n",
      "Epoch 66/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4075 - accuracy: 0.8062\n",
      "Epoch 67/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8115\n",
      "Epoch 68/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4026 - accuracy: 0.8101\n",
      "Epoch 69/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4019 - accuracy: 0.8083\n",
      "Epoch 70/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8094\n",
      "Epoch 71/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8155\n",
      "Epoch 72/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3981 - accuracy: 0.8126\n",
      "Epoch 73/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3985 - accuracy: 0.8105\n",
      "Epoch 74/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3984 - accuracy: 0.8101\n",
      "Epoch 75/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8130\n",
      "Epoch 76/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3949 - accuracy: 0.8183\n",
      "Epoch 77/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3944 - accuracy: 0.8173\n",
      "Epoch 78/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3936 - accuracy: 0.8148\n",
      "Epoch 79/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3929 - accuracy: 0.8176\n",
      "Epoch 80/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3920 - accuracy: 0.8148\n",
      "Epoch 81/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3906 - accuracy: 0.8162\n",
      "Epoch 82/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3888 - accuracy: 0.8198\n",
      "Epoch 83/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3902 - accuracy: 0.8176\n",
      "Epoch 84/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8194\n",
      "Epoch 85/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8155\n",
      "Epoch 86/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8140\n",
      "Epoch 87/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8216\n",
      "Epoch 88/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8205\n",
      "Epoch 89/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8241\n",
      "Epoch 90/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8194\n",
      "Epoch 91/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3813 - accuracy: 0.8201\n",
      "Epoch 92/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3812 - accuracy: 0.8209\n",
      "Epoch 93/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3781 - accuracy: 0.8252\n",
      "Epoch 94/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3794 - accuracy: 0.8230\n",
      "Epoch 95/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3785 - accuracy: 0.8241\n",
      "Epoch 96/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3763 - accuracy: 0.8269\n",
      "Epoch 97/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8320\n",
      "Epoch 98/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8277\n",
      "Epoch 99/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3749 - accuracy: 0.8252\n",
      "Epoch 100/100\n",
      "88/88 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8237\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model_2 = snap_model_2.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 0s - loss: 0.4474 - accuracy: 0.7981 - 405ms/epoch - 14ms/step\n",
      "Loss: 0.447407603263855, Accuracy: 0.7980666160583496\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = snap_model_2.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION: Changing to activation function to tanh may be advantageous because tanh is centered around 0 [-1 to 1], whereas relu is less centered [0 to infinity]. This may be because our y feature is binary in nature (1 = yes, 0 = no)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model\n",
    "snap_model_2.save(\"snap_participation.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
